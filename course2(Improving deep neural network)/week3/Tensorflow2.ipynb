{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcpBg7_wFmN3",
        "outputId": "ce95188f-c2e1-4824-ab5c-5b5c5608a66a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Desktop/PythonP/week3\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/Desktop/PythonP/week3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV9vNszuK08w"
      },
      "source": [
        "1. **IMPORT ALL THE NECESSARY PACKAGES** . THIS TIME INSTEAD OF USING SESSION IN OLDER VERSION OF TENSORFLOW WE WILL USE EAGER TENSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ap5ivfaHHxYw"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "from tensorflow.python.ops.resource_variable_ops import ResourceVariable\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cJEKqpucIK4p",
        "outputId": "08bc5a32-c170-450d-c6e0-f63b8627ba3c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.15.0'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checking the version of tensorflow\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9SNEDn2fIN5W"
      },
      "outputs": [],
      "source": [
        "train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
        "test_dataset = h5py.File('datasets/test_signs.h5', \"r\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YX4DRAuIN-i",
        "outputId": "93dcfe4b-9bc0-4068-8bca-14b7e379e7da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<HDF5 dataset \"train_set_x\": shape (1080, 64, 64, 3), type \"|u1\">"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset['train_set_x']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CqSmB80LPvD"
      },
      "source": [
        "In case the data set is not a tensor data set the functions will give error . make sure it is a tensor data set or convert into one\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yLdn3qXZIUEC"
      },
      "outputs": [],
      "source": [
        "# tf.data.Dataset.from_tensor_slices( list_or_numpy_array ) creates TensorFlow Datasets\n",
        "x_train = tf.data.Dataset.from_tensor_slices(train_dataset['train_set_x'])\n",
        "y_train = tf.data.Dataset.from_tensor_slices(train_dataset['train_set_y'])\n",
        "\n",
        "x_test = tf.data.Dataset.from_tensor_slices(test_dataset['test_set_x'])\n",
        "y_test = tf.data.Dataset.from_tensor_slices(test_dataset['test_set_y'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUSAFx5xIWlL",
        "outputId": "fe1f004c-7801-4f1f-bcc0-9da2c32cd53d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4-5T6G3IYYJ",
        "outputId": "43a7a8a4-4820-494d-8814-acd9d392ff9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorSpec(shape=(64, 64, 3), dtype=tf.uint8, name=None)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.element_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhZYopxoIaTQ",
        "outputId": "5f046e06-8152-46c7-e3d1-c937ba52ade6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[227 220 214]\n",
            "  [227 221 215]\n",
            "  [227 222 215]\n",
            "  ...\n",
            "  [232 230 224]\n",
            "  [231 229 222]\n",
            "  [230 229 221]]\n",
            "\n",
            " [[227 221 214]\n",
            "  [227 221 215]\n",
            "  [228 221 215]\n",
            "  ...\n",
            "  [232 230 224]\n",
            "  [231 229 222]\n",
            "  [231 229 221]]\n",
            "\n",
            " [[227 221 214]\n",
            "  [227 221 214]\n",
            "  [227 221 215]\n",
            "  ...\n",
            "  [232 230 224]\n",
            "  [231 229 223]\n",
            "  [230 229 221]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[119  81  51]\n",
            "  [124  85  55]\n",
            "  [127  87  58]\n",
            "  ...\n",
            "  [210 211 211]\n",
            "  [211 212 210]\n",
            "  [210 211 210]]\n",
            "\n",
            " [[119  79  51]\n",
            "  [124  84  55]\n",
            "  [126  85  56]\n",
            "  ...\n",
            "  [210 211 210]\n",
            "  [210 211 210]\n",
            "  [209 210 209]]\n",
            "\n",
            " [[119  81  51]\n",
            "  [123  83  55]\n",
            "  [122  82  54]\n",
            "  ...\n",
            "  [209 210 210]\n",
            "  [209 210 209]\n",
            "  [208 209 209]]], shape=(64, 64, 3), dtype=uint8)\n"
          ]
        }
      ],
      "source": [
        "print(next(iter(x_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qusHSF3IcuE",
        "outputId": "e8cf4083-bc04-46af-cc6d-ace0468c486c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[227 220 214]\n",
            "  [227 221 215]\n",
            "  [227 222 215]\n",
            "  ...\n",
            "  [232 230 224]\n",
            "  [231 229 222]\n",
            "  [230 229 221]]\n",
            "\n",
            " [[227 221 214]\n",
            "  [227 221 215]\n",
            "  [228 221 215]\n",
            "  ...\n",
            "  [232 230 224]\n",
            "  [231 229 222]\n",
            "  [231 229 221]]\n",
            "\n",
            " [[227 221 214]\n",
            "  [227 221 214]\n",
            "  [227 221 215]\n",
            "  ...\n",
            "  [232 230 224]\n",
            "  [231 229 223]\n",
            "  [230 229 221]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[119  81  51]\n",
            "  [124  85  55]\n",
            "  [127  87  58]\n",
            "  ...\n",
            "  [210 211 211]\n",
            "  [211 212 210]\n",
            "  [210 211 210]]\n",
            "\n",
            " [[119  79  51]\n",
            "  [124  84  55]\n",
            "  [126  85  56]\n",
            "  ...\n",
            "  [210 211 210]\n",
            "  [210 211 210]\n",
            "  [209 210 209]]\n",
            "\n",
            " [[119  81  51]\n",
            "  [123  83  55]\n",
            "  [122  82  54]\n",
            "  ...\n",
            "  [209 210 210]\n",
            "  [209 210 209]\n",
            "  [208 209 209]]], shape=(64, 64, 3), dtype=uint8)\n"
          ]
        }
      ],
      "source": [
        "for element in x_train:\n",
        "  print(element)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5r2vsIWLu0k"
      },
      "source": [
        "There's one more additional difference between TensorFlow datasets and Numpy arrays: If you need to transform one, you would invoke the map method to apply the function passed as an argument to each of the elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WGaOphS8IjLj"
      },
      "outputs": [],
      "source": [
        "def normalize(image):\n",
        "    \"\"\"\n",
        "    Transform an image into a tensor of shape (64 * 64 * 3, 1)\n",
        "    and normalize its components.\n",
        "\n",
        "    Arguments\n",
        "    image - Tensor.\n",
        "\n",
        "    Returns:\n",
        "    result -- Transformed tensor\n",
        "    \"\"\"\n",
        "    image = tf.cast(image, tf.float32) / 256.0\n",
        "    image = tf.reshape(image, [-1,1])\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cr4KxYU9IkOa"
      },
      "outputs": [],
      "source": [
        "new_train = x_train.map(normalize)\n",
        "new_test = x_test.map(normalize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWWwGu2vIl9a",
        "outputId": "68b46f6e-6112-4ac4-cad5-53a3a5bbe1fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorSpec(shape=(12288, 1), dtype=tf.float32, name=None)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_train.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8fJ1QxCInaK",
        "outputId": "c9e871d9-1c36-4425-a9b7-09c481517ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.88671875]\n",
            " [0.859375  ]\n",
            " [0.8359375 ]\n",
            " ...\n",
            " [0.8125    ]\n",
            " [0.81640625]\n",
            " [0.81640625]], shape=(12288, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(next(iter(new_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjEzkkvpL1FM"
      },
      "source": [
        "2.1 - Linear Function\n",
        "Let's begin this programming exercise by computing the following equation: Y = WX+b , where W  and X are random matrices and b is a random vector.\n",
        "\n",
        "Exercise 1 - linear_function\n",
        "Compute WX+b where W , X  and b\n",
        " are drawn from a random normal distribution. W is of shape (4, 3), X is (3,1) and b is (4,1). As an example, this is how to define a constant X with the shape (3,1):\n",
        "\n",
        "X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
        "Note that the difference between tf.constant and tf.Variable is that you can modify the state of a tf.Variable but cannot change the state of a tf.constant.\n",
        "\n",
        "You might find the following functions helpful:\n",
        "\n",
        "tf.matmul(..., ...) to do a matrix multiplication\n",
        "tf.add(..., ...) to do an addition\n",
        "np.random.randn(...) to initialize randomly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tE_wtPOcIpKF"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: linear_function\n",
        "\n",
        "def linear_function():\n",
        "    \"\"\"\n",
        "    Implements a linear function:\n",
        "            Initializes X to be a random tensor of shape (3,1)\n",
        "            Initializes W to be a random tensor of shape (4,3)\n",
        "            Initializes b to be a random tensor of shape (4,1)\n",
        "    Returns:\n",
        "    result -- Y = WX + b\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(1)\n",
        "\n",
        "    \"\"\"\n",
        "    Note, to ensure that the \"random\" numbers generated match the expected results,\n",
        "    please create the variables in the order given in the starting code below.\n",
        "    (Do not re-arrange the order).\n",
        "    \"\"\"\n",
        "    # (approx. 4 lines)\n",
        "    # X = ...\n",
        "    # W = ...\n",
        "    # b = ...\n",
        "    # Y = ...\n",
        "    # YOUR CODE STARTS HERE\n",
        "    X = tf.constant(np.random.randn(3,1))\n",
        "    W = tf.constant(np.random.randn(4,3))\n",
        "    b = tf.constant(np.random.randn(4,1))\n",
        "    Y = tf.add(tf.matmul(W,X),b)\n",
        "\n",
        "    # YOUR CODE ENDS HERE\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga_wY42UItN-",
        "outputId": "257ff1a2-25d5-44de-ec5d-bad0e5438013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-2.15657382]\n",
            " [ 2.95891446]\n",
            " [-1.08926781]\n",
            " [-0.84538042]], shape=(4, 1), dtype=float64)\n",
            "\u001b[92mAll test passed\n"
          ]
        }
      ],
      "source": [
        "result = linear_function()\n",
        "print(result)\n",
        "\n",
        "assert type(result) == EagerTensor, \"Use the TensorFlow API\"\n",
        "assert np.allclose(result, [[-2.15657382], [ 2.95891446], [-1.08926781], [-0.84538042]]), \"Error\"\n",
        "print(\"\\033[92mAll test passed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j0mVjvCMRXj"
      },
      "source": [
        "2.2 - Computing the Sigmoid\n",
        "Amazing! You just implemented a linear function. TensorFlow offers a variety of commonly used neural network functions like tf.sigmoid and tf.softmax.\n",
        "\n",
        "For this exercise, compute the sigmoid of z.\n",
        "\n",
        "In this exercise, you will: Cast your tensor to type float32 using tf.cast, then compute the sigmoid using tf.keras.activations.sigmoid.\n",
        "\n",
        "\n",
        "Exercise 2 - sigmoid\n",
        "Implement the sigmoid function below. You should use the following:\n",
        "\n",
        "tf.cast(\"...\", tf.float32)\n",
        "tf.keras.activations.sigmoid(\"...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5mwpkrLAIupo"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: sigmoid\n",
        "\n",
        "def sigmoid(z):\n",
        "\n",
        "    \"\"\"\n",
        "    Computes the sigmoid of z\n",
        "\n",
        "    Arguments:\n",
        "    z -- input value, scalar or vector\n",
        "\n",
        "    Returns:\n",
        "    a -- (tf.float32) the sigmoid of z\n",
        "    \"\"\"\n",
        "    # tf.keras.activations.sigmoid requires float16, float32, float64, complex64, or complex128.\n",
        "\n",
        "    # (approx. 2 lines)\n",
        "    # z = ...\n",
        "    # result = ...\n",
        "    # YOUR CODE STARTS HERE\n",
        "    z = tf.cast(z,tf.float32)\n",
        "    a = tf.keras.activations.sigmoid(z)\n",
        "    # YOUR CODE ENDS HERE\n",
        "    return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIymZ_slIx7H",
        "outputId": "a9f4de64-e648-4387-9289-bfd0aed300d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "dtype: <dtype: 'float32'>\n",
            "sigmoid(-1) = tf.Tensor(0.26894143, shape=(), dtype=float32)\n",
            "sigmoid(0) = tf.Tensor(0.5, shape=(), dtype=float32)\n",
            "sigmoid(12) = tf.Tensor(0.99999386, shape=(), dtype=float32)\n",
            "\u001b[92mAll test passed\n"
          ]
        }
      ],
      "source": [
        "result = sigmoid(-1)\n",
        "print (\"type: \" + str(type(result)))\n",
        "print (\"dtype: \" + str(result.dtype))\n",
        "print (\"sigmoid(-1) = \" + str(result))\n",
        "print (\"sigmoid(0) = \" + str(sigmoid(0.0)))\n",
        "print (\"sigmoid(12) = \" + str(sigmoid(12)))\n",
        "\n",
        "def sigmoid_test(target):\n",
        "    result = target(0)\n",
        "    assert(type(result) == EagerTensor)\n",
        "    assert (result.dtype == tf.float32)\n",
        "    assert sigmoid(0) == 0.5, \"Error\"\n",
        "    assert sigmoid(-1) == 0.26894143, \"Error\"\n",
        "\n",
        "\n",
        "    print(\"\\033[92mAll test passed\")\n",
        "\n",
        "sigmoid_test(sigmoid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irTtyzWaMebn"
      },
      "source": [
        "This is called \"one hot\" encoding, because in the converted representation, exactly one element of each column is \"hot\" (meaning set to 1). To do this conversion in numpy, you might have to write a few lines of code. In TensorFlow, you can use one line of code:\n",
        "\n",
        "tf.one_hot(labels, depth, axis=0)\n",
        "axis=0 indicates the new axis is created at dimension 0\n",
        "Exercise 3 - one_hot_matrix\n",
        "Implement the function below to take one label and the total number of classes\n",
        ", and return the one hot encoding in a column whise matrix. Use tf.one_hot() to do this, and tf.reshape() to reshape your one hot tensor!\n",
        "\n",
        "tf.reshape(tensor, shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yULty0EfJDSR"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: one_hot_matrix\n",
        "def one_hot_matrix(label, depth=6):\n",
        "    \"\"\"\n",
        "    Computes the one hot encoding for a single label\n",
        "\n",
        "    Arguments:\n",
        "        label --  (int) Categorical labels\n",
        "        depth --  (int) Number of different classes that label can take\n",
        "\n",
        "    Returns:\n",
        "         one_hot -- tf.Tensor A single-column matrix with the one hot encoding.\n",
        "    \"\"\"\n",
        "    # (approx. 1 line)\n",
        "    # one_hot = ...\n",
        "    # YOUR CODE STARTS HERE\n",
        "    one_hot = tf.one_hot(label,depth,axis=0)\n",
        "    one_hot = tf.reshape(one_hot,[depth,1])\n",
        "\n",
        "    # YOUR CODE ENDS HERE\n",
        "    return one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyPrMBGuJGP4",
        "outputId": "d91fd08b-9c6a-40ac-dc92-6a5632451753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]], shape=(4, 1), dtype=float32)\n",
            "\u001b[92mAll test passed\n"
          ]
        }
      ],
      "source": [
        "def one_hot_matrix_test(target):\n",
        "    label = tf.constant(1)\n",
        "    depth = 4\n",
        "    result = target(label, depth)\n",
        "    print(result)\n",
        "    assert result.shape[0] == depth, \"Use the parameter depth\"\n",
        "    assert result.shape[1] == 1, f\"Reshape to have only 1 column\"\n",
        "    assert np.allclose(result,  [[0.], [1.], [0.], [0.]] ), \"Wrong output. Use tf.one_hot\"\n",
        "    result = target(3, depth)\n",
        "    assert np.allclose(result, [[0.], [0.], [0.], [1.]] ), \"Wrong output. Use tf.one_hot\"\n",
        "\n",
        "    print(\"\\033[92mAll test passed\")\n",
        "\n",
        "one_hot_matrix_test(one_hot_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "p8tSY19XJGU_"
      },
      "outputs": [],
      "source": [
        "new_y_test = y_test.map(one_hot_matrix)\n",
        "new_y_train = y_train.map(one_hot_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_6rKh0bJLDz",
        "outputId": "6d35e89d-ab36-4f05-d78c-a20cd71d3f50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]], shape=(6, 1), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(next(iter(new_y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RkZ_AxkMpD7"
      },
      "source": [
        "2.4 - Initialize the Parameters\n",
        "Now you'll initialize a vector of numbers between zero and one. The function you'll be calling is tf.keras.initializers.GlorotNormal, which draws samples from a truncated normal distribution centered on 0, with stddev = sqrt(2 / (fan_in + fan_out)), where fan_in is the number of input units and fan_out is the number of output units, both in the weight tensor.\n",
        "\n",
        "To initialize with zeros or ones you could use tf.zeros() or tf.ones() instead.\n",
        "\n",
        "\n",
        "Exercise 4 - initialize_parameters\n",
        "Implement the function below to take in a shape and to return an array of numbers between -1 and 1.\n",
        "\n",
        "tf.keras.initializers.GlorotNormal(seed=1)\n",
        "tf.Variable(initializer(shape=())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "E0hns2dIJM2I"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: initialize_parameters\n",
        "\n",
        "def initialize_parameters():\n",
        "    \"\"\"\n",
        "    Initializes parameters to build a neural network with TensorFlow. The shapes are:\n",
        "                        W1 : [25, 12288]\n",
        "                        b1 : [25, 1]\n",
        "                        W2 : [12, 25]\n",
        "                        b2 : [12, 1]\n",
        "                        W3 : [6, 12]\n",
        "                        b3 : [6, 1]\n",
        "\n",
        "    Returns:\n",
        "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
        "    \"\"\"\n",
        "\n",
        "    initializer = tf.keras.initializers.GlorotNormal(seed=1)\n",
        "    #(approx. 6 lines of code)\n",
        "    W1 = tf.Variable(initializer(shape=(25, 12288)))\n",
        "    b1 = tf.Variable(initializer(shape=(25, 1)))\n",
        "    W2 = tf.Variable(initializer(shape=(12, 25)))\n",
        "    b2 = tf.Variable(initializer(shape=(12, 1)))\n",
        "    W3 = tf.Variable(initializer(shape=(6,12)))\n",
        "    b3 = tf.Variable(initializer(shape=(6, 1)))\n",
        "    # YOUR CODE STARTS HERE\n",
        "\n",
        "\n",
        "    # YOUR CODE ENDS HERE\n",
        "\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2,\n",
        "                  \"W3\": W3,\n",
        "                  \"b3\": b3}\n",
        "\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUW9AdJxJQ4d",
        "outputId": "08d9e64f-ea89-4eb8-c10f-3677ccc5a8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W1 shape: (25, 12288)\n",
            "b1 shape: (25, 1)\n",
            "W2 shape: (12, 25)\n",
            "b2 shape: (12, 1)\n",
            "W3 shape: (6, 12)\n",
            "b3 shape: (6, 1)\n",
            "\u001b[92mAll test passed\n"
          ]
        }
      ],
      "source": [
        "def initialize_parameters_test(target):\n",
        "    parameters = target()\n",
        "\n",
        "    values = {\"W1\": (25, 12288),\n",
        "              \"b1\": (25, 1),\n",
        "              \"W2\": (12, 25),\n",
        "              \"b2\": (12, 1),\n",
        "              \"W3\": (6, 12),\n",
        "              \"b3\": (6, 1)}\n",
        "\n",
        "    for key in parameters:\n",
        "        print(f\"{key} shape: {tuple(parameters[key].shape)}\")\n",
        "        assert type(parameters[key]) == ResourceVariable, \"All parameter must be created using tf.Variable\"\n",
        "        assert tuple(parameters[key].shape) == values[key], f\"{key}: wrong shape\"\n",
        "        assert np.abs(np.mean(parameters[key].numpy())) < 0.5,  f\"{key}: Use the GlorotNormal initializer\"\n",
        "        assert np.std(parameters[key].numpy()) > 0 and np.std(parameters[key].numpy()) < 1, f\"{key}: Use the GlorotNormal initializer\"\n",
        "\n",
        "    print(\"\\033[92mAll test passed\")\n",
        "\n",
        "initialize_parameters_test(initialize_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EgwlV8qeJUBf"
      },
      "outputs": [],
      "source": [
        "parameters = initialize_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I66u46qCMwDn"
      },
      "source": [
        "3 - Building Your First Neural Network in TensorFlow\n",
        "In this part of the assignment you will build a neural network using TensorFlow. Remember that there are two parts to implementing a TensorFlow model:\n",
        "\n",
        "Implement forward propagation\n",
        "Retrieve the gradients and train the model\n",
        "Let's get into it!\n",
        "\n",
        "\n",
        "3.1 - Implement Forward Propagation\n",
        "One of TensorFlow's great strengths lies in the fact that you only need to implement the forward propagation function.\n",
        "\n",
        "Here, you'll use a TensorFlow decorator, @tf.function, which builds a computational graph to execute the function. @tf.function is polymorphic, which comes in very handy, as it can support arguments with different data types or shapes, and be used with other languages, such as Python. This means that you can use data dependent control flow statements.\n",
        "\n",
        "When you use @tf.function to implement forward propagation, the computational graph is activated, which keeps track of the operations. This is so you can calculate your gradients with backpropagation.\n",
        "\n",
        "\n",
        "Exercise 5 - forward_propagation\n",
        "Implement the forward_propagation function.\n",
        "\n",
        "Note Use only the TF API.\n",
        "\n",
        "tf.math.add\n",
        "tf.linalg.matmul\n",
        "tf.keras.activations.relu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Zp_v6uyKJYjt"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: forward_propagation\n",
        "\n",
        "@tf.function\n",
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR\n",
        "\n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "\n",
        "    # Retrieve the parameters from the dictionary \"parameters\"\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "\n",
        "    #(approx. 5 lines)                   # Numpy Equivalents:\n",
        "    Z1 = tf.add(tf.matmul(W1,X),b1)    # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.keras.activations.relu(Z1) # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2,A1),b2)   # Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = tf.keras.activations.relu(Z2) # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3,A2),b3)   # Z3 = np.dot(W3, A2) + b3\n",
        "    # YOUR CODE STARTS HERE\n",
        "\n",
        "\n",
        "    # YOUR CODE ENDS HERE\n",
        "\n",
        "    return Z3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5GVOVb6JcjW",
        "outputId": "b408908a-122c-460d-85e3-795b68f26bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-0.13082159]\n",
            " [ 0.21228778]\n",
            " [ 0.7050022 ]\n",
            " [-1.1224034 ]\n",
            " [-0.20386729]\n",
            " [ 0.9526217 ]], shape=(6, 1), dtype=float32)\n",
            "\u001b[92mAll test passed\n"
          ]
        }
      ],
      "source": [
        "def forward_propagation_test(target, examples):\n",
        "    for batch in examples:\n",
        "        forward_pass = target(batch, parameters)\n",
        "        assert type(forward_pass) == EagerTensor, \"Your output is not a tensor\"\n",
        "        assert forward_pass.shape == (6, 1), \"Last layer must use W3 and b3\"\n",
        "        assert np.any(forward_pass < 0), \"Don't use a ReLu layer at end of your network\"\n",
        "        assert np.allclose(forward_pass,\n",
        "                           [[-0.13082162],\n",
        "                           [ 0.21228778],\n",
        "                           [ 0.7050022 ],\n",
        "                           [-1.1224034 ],\n",
        "                           [-0.20386729],\n",
        "                           [ 0.9526217 ]]), \"Output does not match\"\n",
        "        print(forward_pass)\n",
        "        break\n",
        "\n",
        "\n",
        "    print(\"\\033[92mAll test passed\")\n",
        "\n",
        "forward_propagation_test(forward_propagation, new_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbPelPtEM0K-"
      },
      "source": [
        "3.2 Compute the Cost\n",
        "Here again, the delightful @tf.function decorator steps in and saves you time. All you need to do is specify how to compute the cost, and you can do so in one simple step by using:\n",
        "\n",
        "tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_true = ..., y_pred = ..., from_logits=True))\n",
        "\n",
        "\n",
        "Exercise 6 - compute_cost\n",
        "Implement the cost function below.\n",
        "\n",
        "It's important to note that the \"y_pred\" and \"y_true\" inputs of tf.keras.losses.binary_crossentropy are expected to be of shape (number of examples, num_classes). Since both the transpose and the original tensors have the same values, just in different order, the result of calculating the binary_crossentropy should be the same if you transpose or not the logits and labels. Just for reference here is how the Binary Cross entropy is calculated in TensorFlow:\n",
        "mean_reduce(max(logits, 0) - logits * labels + log(1 + exp(-abs(logits))), axis=-1)\n",
        "\n",
        "tf.reduce_mean basically does the summation over the examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "K1RqRhXgJfT6"
      },
      "outputs": [],
      "source": [
        "# GRADED FUNCTION: compute_cost\n",
        "\n",
        "@tf.function\n",
        "def compute_cost(logits, labels):\n",
        "    \"\"\"\n",
        "    Computes the cost\n",
        "\n",
        "    Arguments:\n",
        "    logits -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
        "    labels -- \"true\" labels vector, same shape as Z3\n",
        "\n",
        "    Returns:\n",
        "    cost - Tensor of the cost function\n",
        "    \"\"\"\n",
        "\n",
        "    #(1 line of code)\n",
        "    # cost = ...\n",
        "    # YOUR CODE STARTS HERE\n",
        "    cost = tf.reduce_mean(tf.keras.losses.binary_crossentropy(labels,logits,from_logits=True))\n",
        "\n",
        "    # YOUR CODE ENDS HERE\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjNcgEy1JjdE",
        "outputId": "3f89cd72-02b4-4a80-f0f6-618b39e60e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.8419182681095858, shape=(), dtype=float64)\n",
            "\u001b[92mAll test passed\n"
          ]
        }
      ],
      "source": [
        "def compute_cost_test(target):\n",
        "    labels = np.array([[0., 1.], [0., 0.], [1., 0.]])\n",
        "    logits = np.array([[0.6, 0.4], [0.4, 0.6], [0.4, 0.6]])\n",
        "    result = compute_cost(logits, labels)\n",
        "    print(result)\n",
        "    assert(type(result) == EagerTensor), \"Use the TensorFlow API\"\n",
        "    assert (np.abs(result - (0.7752516 +  0.9752516 + 0.7752516) / 3.0) < 1e-7), \"Test does not match. Did you get the mean of your cost functions?\"\n",
        "\n",
        "    print(\"\\033[92mAll test passed\")\n",
        "\n",
        "compute_cost_test(compute_cost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzDlPkFkM8du"
      },
      "source": [
        "Train the Model\n",
        "Let's talk optimizers. You'll specify the type of optimizer in one line, in this case tf.keras.optimizers.Adam (though you can use others such as SGD), and then call it within the training loop.\n",
        "\n",
        "Notice the tape.gradient function: this allows you to retrieve the operations recorded for automatic differentiation inside the GradientTape block. Then, calling the optimizer method apply_gradients, will apply the optimizer's update rules to each trainable parameter. At the end of this assignment, you'll find some documentation that explains this more in detail, but for now, a simple explanation will do. ;)\n",
        "\n",
        "Here you should take note of an important extra step that's been added to the batch training process:\n",
        "\n",
        "tf.Data.dataset = dataset.prefetch(8)\n",
        "What this does is prevent a memory bottleneck that can occur when reading from disk. prefetch() sets aside some data and keeps it ready for when it's needed. It does this by creating a source dataset from your input data, applying a transformation to preprocess the data, then iterating over the dataset the specified number of elements at a time. This works because the iteration is streaming, so the data doesn't need to fit into the memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "EL79s6uPJl_-"
      },
      "outputs": [],
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
        "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
        "    \"\"\"\n",
        "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
        "\n",
        "    Arguments:\n",
        "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
        "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
        "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
        "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
        "    learning_rate -- learning rate of the optimization\n",
        "    num_epochs -- number of epochs of the optimization loop\n",
        "    minibatch_size -- size of a minibatch\n",
        "    print_cost -- True to print the cost every 100 epochs\n",
        "\n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "\n",
        "    costs = []                                        # To keep track of the cost\n",
        "\n",
        "    # Initialize your parameters\n",
        "    #(1 line)\n",
        "    parameters = initialize_parameters()\n",
        "\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "    X_train = X_train.batch(minibatch_size, drop_remainder=True).prefetch(8)# <<< extra step\n",
        "    Y_train = Y_train.batch(minibatch_size, drop_remainder=True).prefetch(8) # loads memory faster\n",
        "    # Create a directory to save the checkpoints\n",
        "    checkpoint_dir = \"training_checkpoints\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Define the checkpoint path\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, \"cp-{epoch:04d}.ckpt\")\n",
        "\n",
        "    # Create a callback that saves the model's weights after every epoch\n",
        "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                     save_weights_only=True,\n",
        "                                                     save_freq='epoch',  # Save after every epoch\n",
        "                                                     verbose=1)\n",
        "    # Do the training loop\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        epoch_cost = 0.\n",
        "\n",
        "        for (minibatch_X, minibatch_Y) in zip(X_train, Y_train):\n",
        "            # Select a minibatch\n",
        "            with tf.GradientTape() as tape:\n",
        "                # 1. predict\n",
        "                Z3 = forward_propagation(minibatch_X, parameters)\n",
        "                # 2. loss\n",
        "                minibatch_cost = compute_cost(Z3, minibatch_Y)\n",
        "\n",
        "            trainable_variables = [W1, b1, W2, b2, W3, b3]\n",
        "            grads = tape.gradient(minibatch_cost, trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, trainable_variables))\n",
        "            epoch_cost += minibatch_cost / minibatch_size\n",
        "\n",
        "        # Print the cost every epoch\n",
        "        if print_cost == True and epoch % 10 == 0:\n",
        "            print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "        if print_cost == True and epoch % 5 == 0:\n",
        "            costs.append(epoch_cost)\n",
        "\n",
        "    # Plot the cost\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per fives)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "\n",
        "    # Save the parameters in a variable\n",
        "    print (\"Parameters have been trained!\")\n",
        "\n",
        "    return parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "2UirosyAaLI7",
        "outputId": "06456564-d353-4aa9-cebf-c1efc44b2fbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 0.742591\n",
            "Cost after epoch 10: 0.614557\n",
            "Cost after epoch 20: 0.598900\n",
            "Cost after epoch 30: 0.588907\n",
            "Cost after epoch 40: 0.579898\n",
            "Cost after epoch 50: 0.570628\n",
            "Cost after epoch 60: 0.560898\n",
            "Cost after epoch 70: 0.550808\n",
            "Cost after epoch 80: 0.540497\n",
            "Cost after epoch 90: 0.488142\n",
            "Cost after epoch 100: 0.478271\n",
            "Cost after epoch 110: 0.472863\n",
            "Cost after epoch 120: 0.468990\n",
            "Cost after epoch 130: 0.466014\n",
            "Cost after epoch 140: 0.463661\n",
            "Cost after epoch 150: 0.461677\n",
            "Cost after epoch 160: 0.459951\n",
            "Cost after epoch 170: 0.458391\n",
            "Cost after epoch 180: 0.456969\n",
            "Cost after epoch 190: 0.455648\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n"
          ]
        }
      ],
      "source": [
        "trained_parameters  = model(new_train, new_y_train, new_test, new_y_test, num_epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zdn7nyvRadsB",
        "outputId": "eb4740e1-c609-4665-e78d-406abd54ae0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'W1': <tf.Variable 'Variable:0' shape=(25, 12288) dtype=float32, numpy=\n",
            "array([[ 0.00159527, -0.00737913,  0.00893296, ..., -0.01227794,\n",
            "         0.01642206,  0.00506491],\n",
            "       [ 0.02264025,  0.0067227 ,  0.00795862, ...,  0.00284724,\n",
            "         0.01910819,  0.00122853],\n",
            "       [-0.00173585, -0.00872453, -0.01410444, ..., -0.00733837,\n",
            "         0.0205085 , -0.02683027],\n",
            "       ...,\n",
            "       [-0.00126929,  0.01729332,  0.02082342, ...,  0.01709594,\n",
            "         0.00429358, -0.00733263],\n",
            "       [ 0.00268262,  0.004105  ,  0.00936713, ...,  0.01222287,\n",
            "        -0.02717604,  0.01498359],\n",
            "       [-0.00145541,  0.02459595,  0.00339064, ..., -0.02478788,\n",
            "         0.02716016, -0.00306428]], dtype=float32)>, 'b1': <tf.Variable 'Variable:0' shape=(25, 1) dtype=float32, numpy=\n",
            "array([[ 0.03964256],\n",
            "       [-0.15545043],\n",
            "       [ 0.19885883],\n",
            "       [-0.24874453],\n",
            "       [-0.28676757],\n",
            "       [-0.12604603],\n",
            "       [-0.01213098],\n",
            "       [ 0.14784063],\n",
            "       [-0.00413172],\n",
            "       [-0.4408977 ],\n",
            "       [ 0.54054177],\n",
            "       [-0.4345032 ],\n",
            "       [ 0.11763882],\n",
            "       [ 0.21523887],\n",
            "       [-0.06772587],\n",
            "       [-0.16429274],\n",
            "       [-0.05259616],\n",
            "       [-0.18479495],\n",
            "       [-0.00280256],\n",
            "       [-0.06777475],\n",
            "       [ 0.09226809],\n",
            "       [ 0.02067652],\n",
            "       [-0.05682073],\n",
            "       [ 0.37065902],\n",
            "       [ 0.21586621]], dtype=float32)>, 'W2': <tf.Variable 'Variable:0' shape=(12, 25) dtype=float32, numpy=\n",
            "array([[ 0.03270398, -0.13031   ,  0.16566682, -0.20850259, -0.2404858 ,\n",
            "        -0.10598166, -0.01016674,  0.12317107, -0.00411659, -0.3709333 ,\n",
            "         0.45312327, -0.36423257,  0.09766971,  0.18042907, -0.05753208,\n",
            "        -0.13796303, -0.04518652, -0.15597364, -0.00236228, -0.05681378,\n",
            "         0.07734591,  0.01733258, -0.04763132,  0.31054643,  0.18095495],\n",
            "       [ 0.275006  ,  0.0652916 ,  0.19277105,  0.00808901, -0.35061046,\n",
            "        -0.04379591,  0.00529772,  0.14074473, -0.22700697, -0.08254652,\n",
            "        -0.10437229, -0.27877635, -0.22737731, -0.15467171, -0.30434608,\n",
            "         0.42841426,  0.04013019,  0.14082581,  0.40803406,  0.19127996,\n",
            "        -0.08289494,  0.19833343, -0.18854785,  0.11045384, -0.10293514],\n",
            "       [ 0.07370555,  0.12879197, -0.38048682, -0.1428371 , -0.16866712,\n",
            "        -0.12560502,  0.08047906, -0.14222261, -0.3291437 ,  0.11487076,\n",
            "         0.21897362,  0.1428981 ,  0.4108547 , -0.02966296, -0.11487766,\n",
            "         0.2835236 ,  0.2571582 , -0.12365929,  0.1469501 , -0.39992067,\n",
            "        -0.11544652, -0.11918075, -0.5031594 , -0.16647008, -0.0463655 ],\n",
            "       [-0.11886349,  0.19529893, -0.13205278, -0.46206364,  0.07806116,\n",
            "        -0.36992028, -0.06379852,  0.37158278,  0.0755597 ,  0.5198782 ,\n",
            "        -0.01714175,  0.35476214,  0.09361284,  0.17954445,  0.00514452,\n",
            "         0.04280831,  0.1051797 ,  0.03766965, -0.23309673, -0.23678231,\n",
            "        -0.07444265, -0.30713868, -0.11694647,  0.3292588 , -0.09511969],\n",
            "       [ 0.1594041 ,  0.0393942 ,  0.47869283,  0.2265753 ,  0.03725046,\n",
            "        -0.51921755, -0.01731534, -0.31578013, -0.21672064,  0.04122872,\n",
            "         0.04947535, -0.29094276, -0.03152779,  0.47902155,  0.31676546,\n",
            "         0.0473902 ,  0.07770424,  0.3139462 , -0.02500637,  0.10048122,\n",
            "        -0.05332499, -0.34107792, -0.13928485,  0.12402117, -0.41300818],\n",
            "       [-0.14994699,  0.03965309, -0.47870195, -0.07975383,  0.09755022,\n",
            "        -0.00232862, -0.26367775, -0.23967475,  0.24946521,  0.22969191,\n",
            "        -0.30773658,  0.1017215 ,  0.03053034,  0.26468748, -0.51858497,\n",
            "        -0.08669744,  0.03128893,  0.28504866,  0.2072474 , -0.14461054,\n",
            "        -0.09631125,  0.2553377 ,  0.0313108 ,  0.28684467,  0.02228327],\n",
            "       [-0.20329641, -0.2922766 , -0.03024991,  0.00603078,  0.34428513,\n",
            "         0.14932795, -0.42723438,  0.07875892,  0.06157893, -0.19437575,\n",
            "         0.03054013, -0.20949648,  0.2890019 ,  0.03168807,  0.18291238,\n",
            "        -0.17629069, -0.2162296 ,  0.02522451, -0.17976451,  0.20999093,\n",
            "         0.13074148,  0.12900151, -0.29620144,  0.39828372,  0.35581756],\n",
            "       [-0.08132942,  0.0508789 ,  0.03970909, -0.06884057, -0.07758211,\n",
            "         0.21220328,  0.16169944, -0.05766106, -0.04837854, -0.23052695,\n",
            "         0.2551639 , -0.2933403 , -0.16104451, -0.11232601, -0.1305835 ,\n",
            "         0.0502181 ,  0.18621859, -0.07786819,  0.10281896, -0.06372993,\n",
            "         0.41251048, -0.01803587,  0.04746069,  0.27628538, -0.21901166],\n",
            "       [ 0.28539097,  0.20629272, -0.38372156,  0.26297212,  0.2350495 ,\n",
            "         0.18105377,  0.25501856, -0.19114897,  0.355807  ,  0.00106926,\n",
            "        -0.33252424, -0.09722907, -0.00984821,  0.22310142, -0.22939995,\n",
            "        -0.027319  ,  0.18572639, -0.00867896,  0.47467512,  0.00131025,\n",
            "         0.3148377 , -0.22662118,  0.12927507,  0.04265415, -0.45121887],\n",
            "       [-0.23054187, -0.22334962, -0.18913192,  0.15417175, -0.07368277,\n",
            "        -0.0554374 ,  0.12214173,  0.3880139 , -0.01242276,  0.11768965,\n",
            "         0.26777858, -0.06251994, -0.12100054, -0.12495217, -0.03189994,\n",
            "        -0.50085783, -0.09560107, -0.2402923 ,  0.07087833,  0.03642716,\n",
            "        -0.00494978, -0.36984688,  0.00878784,  0.24595837, -0.1323934 ],\n",
            "       [ 0.3191285 ,  0.02266271, -0.06669848, -0.33996752,  0.36436084,\n",
            "        -0.2986556 , -0.0511701 , -0.37243623,  0.27359596,  0.20692125,\n",
            "         0.02171116,  0.10230298, -0.3980014 ,  0.02363082,  0.13089406,\n",
            "         0.3354062 ,  0.08214817,  0.20031573, -0.081278  , -0.28784147,\n",
            "         0.17327178, -0.1326688 ,  0.28894275, -0.19869894, -0.03405774],\n",
            "       [ 0.18820512, -0.20398362, -0.03503615, -0.36792815, -0.22963929,\n",
            "         0.23911732, -0.04237934, -0.0165515 , -0.05906188,  0.16423856,\n",
            "        -0.32017106,  0.15379827,  0.14842801, -0.24647985, -0.08833543,\n",
            "         0.13306345,  0.41101247,  0.362632  ,  0.3355143 ,  0.05405051,\n",
            "         0.21186371,  0.0197499 ,  0.45979315,  0.04402945,  0.36662805]],\n",
            "      dtype=float32)>, 'b2': <tf.Variable 'Variable:0' shape=(12, 1) dtype=float32, numpy=\n",
            "array([[ 0.05586328],\n",
            "       [-0.22080165],\n",
            "       [ 0.28016472],\n",
            "       [-0.35078037],\n",
            "       [-0.4071067 ],\n",
            "       [-0.17678553],\n",
            "       [-0.01738933],\n",
            "       [ 0.20840582],\n",
            "       [-0.00978936],\n",
            "       [-0.6255955 ],\n",
            "       [ 0.76646936],\n",
            "       [-0.6127309 ]], dtype=float32)>, 'W3': <tf.Variable 'Variable:0' shape=(6, 12) dtype=float32, numpy=\n",
            "array([[ 0.04761663, -0.1869142 ,  0.23871909, -0.29910955, -0.34814283,\n",
            "        -0.14891681, -0.01468904,  0.17718893, -0.00528874, -0.53165394,\n",
            "         0.6512269 , -0.52562165],\n",
            "       [ 0.14137168,  0.2585655 , -0.08242776, -0.24897614, -0.08694383,\n",
            "        -0.23123945, -0.00362752, -0.08165746,  0.10867161,  0.02485008,\n",
            "        -0.10594384,  0.40712836],\n",
            "       [ 0.2588232 ,  0.39531493,  0.09260565,  0.19811322, -0.02675355,\n",
            "        -0.5141325 , -0.06277467,  0.0073774 ,  0.20107801, -0.3234572 ,\n",
            "        -0.17168574, -0.21085033],\n",
            "       [-0.39999744, -0.32459378, -0.22211906, -0.44647554,  0.60610884,\n",
            "         0.06233876,  0.20539553,  0.5849541 ,  0.27438077, -0.11884821,\n",
            "         0.27649078, -0.2822457 ],\n",
            "       [ 0.15867612, -0.14753199,  0.10718005,  0.20221218, -0.5397337 ,\n",
            "        -0.1961394 , -0.24190293, -0.17912963,  0.11743002, -0.20150405,\n",
            "        -0.45716155,  0.17953752],\n",
            "       [ 0.313728  ,  0.20475906,  0.5910115 , -0.07041358, -0.17219502,\n",
            "         0.39685282,  0.37256533, -0.17371103,  0.2085042 , -0.5733746 ,\n",
            "        -0.18640897, -0.19104898]], dtype=float32)>, 'b3': <tf.Variable 'Variable:0' shape=(6, 1) dtype=float32, numpy=\n",
            "array([[ 0.07464746],\n",
            "       [-0.31648052],\n",
            "       [ 0.3577738 ],\n",
            "       [-0.4854469 ],\n",
            "       [-0.5509957 ],\n",
            "       [-0.24964447]], dtype=float32)>}\n"
          ]
        }
      ],
      "source": [
        "print(trained_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "OhXDbL6lgfUW"
      },
      "outputs": [],
      "source": [
        "def create_model(parameters):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(25, activation='relu', input_shape=(12288,),\n",
        "                              kernel_initializer=tf.constant_initializer(parameters['W1'].numpy()),\n",
        "                              bias_initializer=tf.constant_initializer(parameters['b1'].numpy())),\n",
        "        tf.keras.layers.Dense(12, activation='relu',\n",
        "                              kernel_initializer=tf.constant_initializer(parameters['W2'].numpy()),\n",
        "                              bias_initializer=tf.constant_initializer(parameters['b2'].numpy())),\n",
        "        tf.keras.layers.Dense(6, activation='softmax',\n",
        "                              kernel_initializer=tf.constant_initializer(parameters['W3'].numpy()),\n",
        "                              bias_initializer=tf.constant_initializer(parameters['b3'].numpy()))\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgB5ywEmgiji",
        "outputId": "5b0c7dbf-cece-426c-8806-7132a4fc4076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.src.engine.sequential.Sequential object at 0x7ce0b1183d00>\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "trained_model = create_model(trained_parameters)\n",
        "print(trained_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK6wQ_UINFXr"
      },
      "source": [
        "Congratulations u have successfully completed the model implementation using tensorflow . eager tensor"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
